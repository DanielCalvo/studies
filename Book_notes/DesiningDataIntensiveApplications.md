
Chapters that seemed most relevant and interesting from a quick glance:

## 1. Reliable, Scalable and Maintainable Applications
- Lots of good general wisdom on this first chapter, although nothing particularly groundbreaking
- "In an early age startup or an unproven product it's usually more important to be able to iterate quickly on product features than it is to scale to some hypothetical future load"

- The "Operability: Making life easy for operations" on page 19 contains an excellent summary of some of the things that operations teams should strive to do well

- An application has to meet various requirements in order to be useful
    - Functional requirements
    - Reliability
    - Scalability
    - Maintainability
- The summary on page 22 is very nice too!

## 2. Relational vs document model
- Learning one relational database (like PostgreSQL) and one Document database (like MongoDB?) could be a very good learning exercise!

## 10. Batch processing
- Ha, unix tools rock for data processing! I knew it! :D
- The biggest limitation of Unix tools is that they run only on a single machine
- The author briefly goes over MapReduce. That was really neat. You can get data from multiple sources, map and reduce it. I felt like diving deeper into Hadoop after a cursory read!
- On map-reduce: Putting computation near the data is prefferable

- Stopped on page 404. This is a great chapter, but it goes in too much depth!

## 11. Stream processing
- I did a crash course in Kafka but it would be neat to know more about this!